{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc6039c",
   "metadata": {},
   "source": [
    "# RAG系统实现教程\n",
    "\n",
    "## 1. 环境变量配置\n",
    "首先配置OpenAI API的环境变量，包括API密钥和基础URL。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a0fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境变量加载成功！\n",
      "API密钥前缀: sk-proj-R_...\n",
      "Base URL: https://ai.devtool.tech/proxy/v1\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 加载 .env 文件中的环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 从环境变量获取API密钥\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 检查环境变量是否正确加载\n",
    "if not api_key:\n",
    "    raise ValueError(\"请设置 OPENAI_API_KEY 环境变量\")\n",
    "if not base_url:\n",
    "    raise ValueError(\"请设置 OPENAI_BASE_URL 环境变量\")\n",
    "\n",
    "print(\"环境变量加载成功！\")\n",
    "print(f\"API密钥前缀: {api_key[:10]}...\")\n",
    "print(f\"Base URL: {base_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc968d",
   "metadata": {},
   "source": [
    "## 2. 初始化OpenAI客户端\n",
    "使用环境变量创建OpenAI客户端实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da6b687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI 客户端创建成功！\n"
     ]
    }
   ],
   "source": [
    "# 实例化客户端 - 使用环境变量\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "print(\"OpenAI 客户端创建成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47aafb7",
   "metadata": {},
   "source": [
    "## 3. 导入RAG系统模块\n",
    "导入自定义的RAG系统相关类，包括Embedding、文件读取、向量存储和聊天功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf419d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG import OpenAIEmbedding, ReadFiles, VectorStore, GPT4oChat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7f7f9",
   "metadata": {},
   "source": [
    "## 4. 测试OpenAI Embedding API\n",
    "直接调用OpenAI的embedding API来测试文本向量化功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb9b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0060808719135820866, 0.01937379501760006, 0.01978626847267151, -0.04902195185422897, 0.005962129216641188, -0.05264672636985779, -0.026648342609405518, -0.012949194759130478, 0.0021545535419136286, -0.02132367342710495]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用 embedding API 获取文本的向量表示\n",
    "response = client.embeddings.create(\n",
    "    input=\"测试文本\",  # 输入文本\n",
    "    model=\"text-embedding-3-small\"  # 选择 Embedding 模型\n",
    ")\n",
    "\n",
    "# 打印返回的embedding向量\n",
    "print(response.data[0].embedding[:10])\n",
    "\n",
    "# 获取embedding长度\n",
    "len(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c3168",
   "metadata": {},
   "source": [
    "## 5. 使用自定义Embedding类\n",
    "使用封装好的OpenAIEmbedding类来获取文本的向量表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a970ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本的向量表示为： [0.026480568572878838, 0.013057298958301544, -0.007077604997903109, -0.010436690412461758, 0.019500991329550743, 0.013423269614577293, -0.00191317533608526, 0.035316139459609985, 0.0011117983376607299, -0.026480568572878838]\n",
      "长度为： 3072\n"
     ]
    }
   ],
   "source": [
    "# 初始化 Embedding 模型\n",
    "embedding_model = OpenAIEmbedding()\n",
    "\n",
    "# 输入需要获取向量表示的文本\n",
    "text = \"这是一个示例文本，用于演示 OpenAI Embedding 的使用。\"\n",
    "\n",
    "# 获取文本的向量表示\n",
    "embedding_vector = embedding_model.get_embedding(text, model=\"text-embedding-3-large\")\n",
    "\n",
    "print(\"文本的向量表示为：\", embedding_vector[:10])\n",
    "print(\"长度为：\", len(embedding_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7e5f0",
   "metadata": {},
   "source": [
    "## 6. 计算文本相似度\n",
    "通过比较两个文本的向量表示来计算它们的余弦相似度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760f353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两段文本的余弦相似度为: 0.7661800739633337\n"
     ]
    }
   ],
   "source": [
    "text1 = '我喜欢吃苹果'\n",
    "text2 = \"苹果是我最喜欢吃的水果\"\n",
    "text3 = \"我喜欢用苹果手机\"\n",
    "\n",
    "vector1 = embedding_model.get_embedding(text1)\n",
    "vector2 = embedding_model.get_embedding(text2)\n",
    "\n",
    "similarity = OpenAIEmbedding.cosine_similarity(vector1, vector2)\n",
    "print(f\"两段文本的余弦相似度为: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b24d17",
   "metadata": {},
   "source": [
    "## 7. 重新导入RAG模块\n",
    "为了确保使用最新的模块代码，重新导入RAG系统相关类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f6ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG import OpenAIEmbedding, ReadFiles, VectorStore, GPT4oChat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85442d",
   "metadata": {},
   "source": [
    "## 8. 读取文档文件\n",
    "初始化文件读取器，获取指定目录下的所有支持的文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813deea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "支持的文件列表： ['./data/【人工智能】AI构建者手册2025 | ICONIQ发布68页报告| AI原生公司 | AI赋能公司 | 代理工作流 | 基础设施 | 市场定价 | 团队结构 | 成本预算 | 内部效率 - YouTube.txt']\n"
     ]
    }
   ],
   "source": [
    "# 初始化 ReadFiles 类，指定文件目录路径\n",
    "file_reader = ReadFiles(path=\"./data\")\n",
    "\n",
    "# 获取目录下所有支持的文件类型\n",
    "file_list = file_reader.get_files()\n",
    "print(\"支持的文件列表：\", file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc0d63",
   "metadata": {},
   "source": [
    "## 9. 文档分块处理\n",
    "将读取的文档内容按指定长度进行分块，便于后续的向量化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b20610c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分块后的文档内容： ['`大家好，这里是最佳拍档，我是大飞。不知道大家有没有发现，最近两年AI领域的讨论已经从“要不要做AI”变成了“怎么把AI做好”。从2023年生成式AI爆发开始，到2025年的今天，越来越多的公司不再纠结于AI的可能性，而是埋头在产品开发、团队搭建、成本控制这些实际的问题上。最近，曾经作为管理硅谷众多科技巨头家办的ICONIQ资本，抓住了这个转折点的时机，发布了一份长达68页的报告，拆解了300家正在开发AI产品的软件公司的实战经验。无论是AI原生公司，还是所谓的AI赋能公司，相信它们的踩坑经验、成功做法，都能带给我们很多的启发。今天大飞就来给大家分享一下。\\n\\n', '问题上。最近，曾经作为管理硅谷众多科技巨头家办的ICONIQ资本，抓住了这个转折点的时机，发布了一份长达68页的报告，拆解了300家正在开发AI产品的软件公司的实战经验。无论是AI原生公司，还是所谓的AI赋能公司，相信它们的踩坑经验、成功做法，都能带给我们很多的启发。今天大飞就来给大家分享一下。\\n\\n要聊AI产品的开发，首先我们得搞清楚现在市面上的AI公司到底有哪些类型。根据报告的调研，主要分为两类，分别是AI原生公司和AI赋能公司。AI原生公司指的是核心产品或商业模式完全由AI驱动的公司，它们的价值几乎都来自于模型训练、推理和持续的学习，这类公司在调研中占了32%，它们的特点是产品的迭代速度非常快。报告里提到，只有1%的AI原生公司还停留在产品发布前的阶段，而AI赋能公司则有11%卡在这个阶段；更关键的是，47%的AI原生产品已经进入了规模化的阶段，也就是说产品已经验证了市场契合度，正在快速扩大用户群和基础设施。这背后可能的原因是，AI原生公司在团队构成、基础设施和融资模式上更有优势，能够更快的跳过试错阶段，而AI赋能公司往往需要把AI“嫁接”到现有的工作流中，难免就会遇到更多的阻碍。', '段；更关键的是，47%的AI原生产品已经进入了规模化的阶段，也就是说产品已经验证了市场契合度，正在快速扩大用户群和基础设施。这背后可能的原因是，AI原生公司在团队构成、基础设施和融资模式上更有优势，能够更快的跳过试错阶段，而AI赋能公司往往需要把AI“嫁接”到现有的工作流中，难免就会遇到更多的阻碍。AI赋能公司则分为两种，一种是在旗舰产品中嵌入AI功能，比如给现有的CRM系统加一个AI推荐模块，这类公司占31%；另一种是开发独立于核心业务的AI产品，比如一个做协作工具的公司，额外再推出一个AI写作助手，这类公司占37%。对于这些公司来说，AI更像是一个提升现有产品价值的工具，而不是全部。比如Salesforce、Atlassian这些传统SaaS巨头，现在都在核心产品里面加入了AI功能，目的是提升自动化、个性化和用户的生产力，但是底层的商业模式和用户体验并没有大的改变。这两种路径的差异，从一开始就决定了它们在产品开发、团队搭建甚至成本结构上的不同。\\n\\n', '有产品价值的工具，而不是全部。比如Salesforce、Atlassian这些传统SaaS巨头，现在都在核心产品里面加入了AI功能，目的是提升自动化、个性化和用户的生产力，但是底层的商业模式和用户体验并没有大的改变。这两种路径的差异，从一开始就决定了它们在产品开发、团队搭建甚至成本结构上的不同。\\n\\n接下来，我们就从产品开发的具体环节来看看这些公司都在做什么，以及它们都遇到了什么问题。不管是AI原生还是AI赋能公司，目前最热门的产品类型基本分为两类：代理工作流和应用层产品。其中，有79%的AI原生公司都在做代理工作流。所谓代理工作流，简单来说就是让AI像“代理Agent”一样去自主完成一系列的任务，比如自动处理客户咨询的全流程，从理解问题到查找资料再到生成回复，甚至能够根据用户的反馈来调整策略。除此之外，垂直领域的AI应用和水平领域的AI应用也很受欢迎，AI原生公司中分别有65%和56%在开发这些应用；而AI赋能公司则占比较低，分别是49%和40%。这也反映了两类公司的不同定位，AI原生公司更专注于通过AI来解决具体的业务流程问题，而AI赋能公司则希望通过AI来增强现有平台的通用性。', '策略。除此之外，垂直领域的AI应用和水平领域的AI应用也很受欢迎，AI原生公司中分别有65%和56%在开发这些应用；而AI赋能公司则占比较低，分别是49%和40%。这也反映了两类公司的不同定位，AI原生公司更专注于通过AI来解决具体的业务流程问题，而AI赋能公司则希望通过AI来增强现有平台的通用性。在模型使用上，有80%的公司会依赖第三方AIAPI，比如GPT和Claude。但是高增长的公司明显更“激进”，77%的高增长公司会在现有的基础模型上微调，54%会从头开发专有模型，而其他公司这两个比例分别是61%和32%。为什么会有这种差异呢？高增长公司通常资源更加充足，而且需要为企业客户提供深度的定制化服务，以及根据客户的数据和需求调整模型，这时候微调或者自研就成了必要选项。而资源有限的公司更倾向于直接用第三方API，这样能最快把产品推向市场，减少前期投入。\\n\\n', '发专有模型，而其他公司这两个比例分别是61%和32%。为什么会有这种差异呢？高增长公司通常资源更加充足，而且需要为企业客户提供深度的定制化服务，以及根据客户的数据和需求调整模型，这时候微调或者自研就成了必要选项。而资源有限的公司更倾向于直接用第三方API，这样能最快把产品推向市场，减少前期投入。\\n\\n从模型的提供商来看，OpenAI的GPT模型依然是绝对主流，有95%的全栈AI公司都在使用，其次是Anthropic的Claude和Google的Gemini。值得注意的是，平均每家公司会用2.8个模型，也就是“多模型的策略”越来越普遍。比如，有的公司在处理简单的文本生成时选择用GPT-4，而处理长文档分析时选择用Claude，处理多模态任务时则使用Gemini，这样既能够优化性能，又能够控制成本，还能避免过度依赖单一的供应商。\\n', 'oogle的Gemini。值得注意的是，平均每家公司会用2.8个模型，也就是“多模型的策略”越来越普遍。比如，有的公司在处理简单的文本生成时选择用GPT-4，而处理长文档分析时选择用Claude，处理多模态任务时则使用Gemini，这样既能够优化性能，又能够控制成本，还能避免过度依赖单一的供应商。\\n在选模型的时候，不同场景的优先级也完全不同。如果是面向客户的产品，准确性是绝对第一位的，74%的公司把它排在第一，而成本排在第二，占比为57%，这和去年的情况很不一样。去年成本在客户产品中几乎是最不重要的，今年排名上升，可能是因为像DeepSeek这样的低成本模型出现，让成本成了更为关键的竞争因素。但如果是内部使用的AI工具，成本就成了头号的考量，占比为74%，其次是准确性，和隐私。毕竟内部工具不直接产生收入，控制成本更重要，而且内部数据往往涉及到机密信息，隐私保护自然也就成了重点。\\n', '乎是最不重要的，今年排名上升，可能是因为像DeepSeek这样的低成本模型出现，让成本成了更为关键的竞争因素。但如果是内部使用的AI工具，成本就成了头号的考量，占比为74%，其次是准确性，和隐私。毕竟内部工具不直接产生收入，控制成本更重要，而且内部数据往往涉及到机密信息，隐私保护自然也就成了重点。\\n在训练和适配技术方面，最常用的是检索增强生成RAG和微调fine-tuning，分别有69%和67%的公司在使用。高增长公司还特别喜欢用提示词技术，比如少样本学习和零样本学习，这可能是因为它们需要快速适配不同客户的需求，而提示词技术能够在不重新训练模型的情况下调整输出。和去年相比，用RAG和微调的公司明显增多了。按理说，基础模型越来越强，微调的需求应该减少，但是实际的情况是，企业客户对定制化的要求更高了，这时候微调依然是必要的。\\n', '用提示词技术，比如少样本学习和零样本学习，这可能是因为它们需要快速适配不同客户的需求，而提示词技术能够在不重新训练模型的情况下调整输出。和去年相比，用RAG和微调的公司明显增多了。按理说，基础模型越来越强，微调的需求应该减少，但是实际的情况是，企业客户对定制化的要求更高了，这时候微调依然是必要的。\\n在部署模型的时候，最大的三个难题分别是幻觉现象、可解释性与信任、以及证明投资回报率ROI，分别占比为39%、38%和34%。另外，计算成本和安全也是比较大的两个问题，比如，一个AI产品上线后，用户量突然增加，API的调用费可能飙升，直接吃掉利润；而如果模型被恶意攻击，生成有害内容，还可能面临法律风险。\\n', '署模型的时候，最大的三个难题分别是幻觉现象、可解释性与信任、以及证明投资回报率ROI，分别占比为39%、38%和34%。另外，计算成本和安全也是比较大的两个问题，比如，一个AI产品上线后，用户量突然增加，API的调用费可能飙升，直接吃掉利润；而如果模型被恶意攻击，生成有害内容，还可能面临法律风险。\\n在基础设施方面，大多数公司都选择了“轻资产”的模式，68%的公司完全使用云服务，64%依赖外部AIAPI提供商。这样做的好处很明显，那就是可以减少前期投入，不用自己维护服务器，还能快速上线产品。但是这也带来了新的问题，供应商的选择、服务等级协议，也就是SLA的谈判，以及按调用次数计费的成本管理，都成了战略级别的事情。如果API提供商突然涨价，或者服务中断，整个产品就会受影响，所以很多公司会和供应商签长期协议，甚至考虑备用方案。只有23%的公司采用了云+本地的混合模式，不到10%完全用本地的基础设施，这些公司往往有着一些特殊的需求，比如金融机构因为合规要求，必须把数据放在自己的服务器里；或者对实时性要求极高，比如自动驾驶的AI模型，需要本地计算来减少延迟。', '产品就会受影响，所以很多公司会和供应商签长期协议，甚至考虑备用方案。只有23%的公司采用了云+本地的混合模式，不到10%完全用本地的基础设施，这些公司往往有着一些特殊的需求，比如金融机构因为合规要求，必须把数据放在自己的服务器里；或者对实时性要求极高，比如自动驾驶的AI模型，需要本地计算来减少延迟。', '产品就会受影响，所以很多公司会和供应商签长期协议，甚至考虑备用方案。只有23%的公司采用了云+本地的混合模式，不到10%完全用本地的基础设施，这些公司往往有着一些特殊的需求，比如金融机构因为合规要求，必须把数据放在自己的服务器里；或者对实时性要求极高，比如自动驾驶的AI模型，需要本地计算来减少延迟。在市场方面，现在最流行的定价模式是混合定价，占比为38%，也就是结合订阅制和按使用量、或者按结果付费。比如，基础的功能收月费，超过一定使用量后额外收费，或者根据AI帮客户节省的成本来抽成。AI赋能型的公司大多会把AI当做一个“增值项”，40%放在高端套餐里，33%免费提供，这其实是把AI作为吸引客户升级或防止客户流失的工具，而不是主要的收入来源。比如很多SaaS工具会说“高级版包含AI分析功能”，以此来推动客户从基础版升级。但是报告指出，这种模式可能不会长久，随着AI的成本越来越高，免费提供会压缩产品的利润空间；而用户使用上的差异很大，重度用户用得多，成本高，轻度用户用得少，收入低，这就会让定价变得很尴尬。所以37%的公司计划在未来12个月调整定价，比如转向更为灵活的按使用量计费，或者根据AI带来的具体价值来定价。', '级。但是报告指出，这种模式可能不会长久，随着AI的成本越来越高，免费提供会压缩产品的利润空间；而用户使用上的差异很大，重度用户用得多，成本高，轻度用户用得少，收入低，这就会让定价变得很尴尬。所以37%的公司计划在未来12个月调整定价，比如转向更为灵活的按使用量计费，或者根据AI带来的具体价值来定价。随着AI产品的规模化，透明度也越来越重要。在产品的规模化阶段，25%的公司会提供详细的模型透明度报告，47%会解释AI如何影响结果，而在pre-launch阶段只有6%会提供详细报告，这其实也很合理，说明产品越成熟，客户越会要求知道AI的工作原理，尤其是对于企业客户来说。\\n\\n', 'I带来的具体价值来定价。随着AI产品的规模化，透明度也越来越重要。在产品的规模化阶段，25%的公司会提供详细的模型透明度报告，47%会解释AI如何影响结果，而在pre-launch阶段只有6%会提供详细报告，这其实也很合理，说明产品越成熟，客户越会要求知道AI的工作原理，尤其是对于企业客户来说。\\n\\n在合规方面，只有13%有专门的AI合规团队，29%的公司有正式的AI伦理和治理政策，47%至少遵守GDPR、CCPA这些数据隐私法，说明很多公司还在“应付”合规，而不是主动去建设合规体系。随着各国的AI监管越来越严，这可能会成为未来的风险点。另外，有66%在用human-in-the-loop的方式，确保AI的公平和安全，简单来说就是在关键决策环节让人类审核，比如AI生成的合同，会让律师再检查一遍。\\n', 'R、CCPA这些数据隐私法，说明很多公司还在“应付”合规，而不是主动去建设合规体系。随着各国的AI监管越来越严，这可能会成为未来的风险点。另外，有66%在用human-in-the-loop的方式，确保AI的公平和安全，简单来说就是在关键决策环节让人类审核，比如AI生成的合同，会让律师再检查一遍。\\n在团队方面，公司规模越大，越可能有专门的AI领导，比如首席AI官、机器学习负责人等等。年收入1亿美元以上的公司中，至少50%都有专门的AI领导，而年收入低于1亿美元的公司只有33%。这是因为规模大了，AI业务更复杂，需要有人去统筹战略、技术和合规，而小公司可能会让CTO或产品负责人直接兼管了。\\n', '。\\n在团队方面，公司规模越大，越可能有专门的AI领导，比如首席AI官、机器学习负责人等等。年收入1亿美元以上的公司中，至少50%都有专门的AI领导，而年收入低于1亿美元的公司只有33%。这是因为规模大了，AI业务更复杂，需要有人去统筹战略、技术和合规，而小公司可能会让CTO或产品负责人直接兼管了。\\n在岗位方面，目前最常见的AI岗位是AI/机器学习工程师，88%的公司都有、有数据科学家的公司占比为72%、有AI产品经理的公司占比67%。但是招人很难，AI/机器学习工程师平均要70天才能招到，数据科学家68天，AI产品经理67天，这比普通工程师难招多了，主要是因为合格的人才少，竞争激烈。还有一些新兴的岗位也在崛起，比如提示工程师和AI设计专家，这些岗位需要懂技术又懂业务，所以现在也成了香饽饽。然而，46%的公司觉得招人不够快，主要原因是“缺乏合格的候选人”，其次是成本高和竞争激烈。有一家公司的技术负责人就说，我们想招有大模型部署经验的工程师，但是市场上这样的人太少了，稍微有点经验的，薪资要求比普通工程师高50%以上，还经常被挖墙脚。因此为了应对，很多公司会自己培养人才，比如让现有工程师参加AI培训，或者和高校合作实习项目。平均来看，公司会计划让20%-30%的工程师专注在AI方面，高增长的公司会更高，甚至能达到37%。这说明AI已经从“边缘项目”变成了“核心业务”，需要足够的工程师去投入。', '通工程师高50%以上，还经常被挖墙脚。因此为了应对，很多公司会自己培养人才，比如让现有工程师参加AI培训，或者和高校合作实习项目。平均来看，公司会计划让20%-30%的工程师专注在AI方面，高增长的公司会更高，甚至能达到37%。这说明AI已经从“边缘项目”变成了“核心业务”，需要足够的工程师去投入。', '通工程师高50%以上，还经常被挖墙脚。因此为了应对，很多公司会自己培养人才，比如让现有工程师参加AI培训，或者和高校合作实习项目。平均来看，公司会计划让20%-30%的工程师专注在AI方面，高增长的公司会更高，甚至能达到37%。这说明AI已经从“边缘项目”变成了“核心业务”，需要足够的工程师去投入。从成本方面来看，AI赋能公司的研发预算中，AI的开发成本大概占10%到20%，年收入越高，比例相对越低，2024年1亿美元以上的公司大约为10%到15%，而低于1亿美元的公司为14%。这可能是因为大公司研发基数大，AI只是其中的一部分，小公司则更聚焦，愿意把更多预算投到AI上。不过，这个比例在2025年有了明显的上涨，普遍增加了5%-10%，说明大家都在加大AI投入。那钱都花到哪里了呢？不同阶段，成本的结构也不一样，在产品发布前，57%的AI预算花在了人才上，因为这时候主要是搭团队、做研发；到了规模化阶段，人才成本占比会降到36%，而基础设施和云成本升到22%，模型推理成本升到13%，这是因为用户多了，服务器、API调用这些“可变的成本”也就上来了。其中，API的使用费是最难控制的，70%的公司把它排在第一，其次是推理成本、模型再训练和更新等等。API的使用费难控制，是因为它和用户的使用量直接挂钩，而用户行为是很难预测的，比如突然有个活动，用户量就会暴涨，API费用可能翻倍。为了省钱，41%的公司在用像Llama3这样的开源模型，37%在尝试优化推理效率，比如压缩模型大小，28%（口误）在用模型蒸馏或者量化技术。举个例子，有的公司把大模型从700亿参数压缩到70亿，推理成本降了70%，性能只降了5%，对很多场景来说完全能接受。', '个活动，用户量就会暴涨，API费用可能翻倍。为了省钱，41%的公司在用像Llama3这样的开源模型，37%在尝试优化推理效率，比如压缩模型大小，28%（口误）在用模型蒸馏或者量化技术。举个例子，有的公司把大模型从700亿参数压缩到70亿，推理成本降了70%，性能只降了5%，对很多场景来说完全能接受。模型训练的月成本也会随着产品的成熟度上升，发布前平均为16.3万美元，规模化阶段为150万美元，推理成本涨得更猛，规模化阶段高增长公司每月要花230万美元，普通公司也要110万美元。数据存储和处理也不便宜，规模化阶段的高增长公司每月要花260万和200万美元，普通公司也要花190万和180万美元。从这些数字我们就能看出，AI产品的“规模化成本”很高，不是光把模型开发出来就行的，还得有足够的资金来支撑后期的运营，这也是很多初创公司需要大笔融资的原因。\\n\\n', '普通公司也要110万美元。数据存储和处理也不便宜，规模化阶段的高增长公司每月要花260万和200万美元，普通公司也要花190万和180万美元。从这些数字我们就能看出，AI产品的“规模化成本”很高，不是光把模型开发出来就行的，还得有足够的资金来支撑后期的运营，这也是很多初创公司需要大笔融资的原因。\\n\\n除了开发对外的AI产品以外，公司也在用AI提升内部的效率，这部分的预算在2025年几乎翻倍。对于年收入10亿美元以上的公司来说，内部AI生产力预算从2024年的平均342万美元涨到2025年的604万美元。在公司内部，有70%左右的员工能够接触到AI工具，但是只有50%会持续使用。大公司则更难推动，年收入10亿美元以上的公司，只有44%的员工持续用AI，而小公司则有57%。这可能是因为大公司流程复杂，员工习惯难改，而且数据安全顾虑更多。纽约人寿的首席数据和分析官唐·武（DonVu）就说，只部署工具肯定不行，尤其是大企业，要让员工真的用起来，得培训、找最积极使用AI的员工来带头，最重要的是高管的持续支持，不然很容易不了了之。', '有44%的员工持续用AI，而小公司则有57%。这可能是因为大公司流程复杂，员工习惯难改，而且数据安全顾虑更多。纽约人寿的首席数据和分析官唐·武（DonVu）就说，只部署工具肯定不行，尤其是大企业，要让员工真的用起来，得培训、找最积极使用AI的员工来带头，最重要的是高管的持续支持，不然很容易不了了之。', '有44%的员工持续用AI，而小公司则有57%。这可能是因为大公司流程复杂，员工习惯难改，而且数据安全顾虑更多。纽约人寿的首席数据和分析官唐·武（DonVu）就说，只部署工具肯定不行，尤其是大企业，要让员工真的用起来，得培训、找最积极使用AI的员工来带头，最重要的是高管的持续支持，不然很容易不了了之。在企业的研发部门内部，最常用的AI场景是编码辅助、内容生成和编写助理，以及文档和知识检索。效果最好的也是编码辅助，65%的公司认为它对生产力的提升最大，高增长公司甚至有33%的代码已经是AI写的，普通公司是27%。但是挑战也是明显的，46%的公司说“找不到合适的使用场景”，42%认为“很难证明ROI”。那么，究竟应该如何衡量内部AI的效果呢？75%的公司会跟踪生产力提升，51%会跟踪成本节省，但只有20%会跟踪收入提升，毕竟内部工具通常都不会直接创造收入。具体方法上，14%只跟踪定量指标，16%只跟踪定性指标，30%既跟踪定量又跟踪定性指标，不过，还有17%的公司完全没开始衡量，这其实是很危险的，因为如果不知道效果，就不知道该优化还是放弃。', '%的公司会跟踪生产力提升，51%会跟踪成本节省，但只有20%会跟踪收入提升，毕竟内部工具通常都不会直接创造收入。具体方法上，14%只跟踪定量指标，16%只跟踪定性指标，30%既跟踪定量又跟踪定性指标，不过，还有17%的公司完全没开始衡量，这其实是很危险的，因为如果不知道效果，就不知道该优化还是放弃。在AI的工具栈方面，PyTorch和TensorFlow这两个深度学习框架最流行，加起来占了一半以上的使用量，但是托管平台也不甘示弱，AWSSageMaker和OpenAI的微调服务用的人也很多，说明团队分成两派，一派喜欢用框架，自己掌控整个过程，一派则喜欢用托管服务，省事。HuggingFace的生态和Databricks的MosaicAITraining也在崛起，它们提供了一些更高层的工具，让训练更简单，比如不用自己写复杂的分布式训练代码，直接调用API就行。\\n\\n', '的微调服务用的人也很多，说明团队分成两派，一派喜欢用框架，自己掌控整个过程，一派则喜欢用托管服务，省事。HuggingFace的生态和Databricks的MosaicAITraining也在崛起，它们提供了一些更高层的工具，让训练更简单，比如不用自己写复杂的分布式训练代码，直接调用API就行。\\n\\n在开发方面，LangChain和HuggingFace的工具集最火，因为它们能简化提示词链、批处理和模型接口这些工作，70%的公司还会用私有或自定义的API，说明很多公司会基于公开模型做二次开发，然后封装成自己的API供内部使用。安全工具也越来越受重视，30%的公司会用Guardrails来做安全检查，防止AI生成有害内容，23%会用Vercel的AISDK进行快速部署，这些工具能让应用更稳定、更合规。\\n', '这些工作，70%的公司还会用私有或自定义的API，说明很多公司会基于公开模型做二次开发，然后封装成自己的API供内部使用。安全工具也越来越受重视，30%的公司会用Guardrails来做安全检查，防止AI生成有害内容，23%会用Vercel的AISDK进行快速部署，这些工具能让应用更稳定、更合规。\\n在监控和观测方面，近一半的公司还在用传统的APM工具，比如Datadog、NewRelic，而不是专门的AI监控工具，这可能是因为这些工具已经融入了现有流程，团队不想再学新的工具。但是专门的AI监控工具也在增长，LangSmith和Weights&Biases各有17%的使用率，它们能够跟踪提示词的效果、检测模型漂移，这些是传统工具做不到的。\\n', 'M工具，比如Datadog、NewRelic，而不是专门的AI监控工具，这可能是因为这些工具已经融入了现有流程，团队不想再学新的工具。但是专门的AI监控工具也在增长，LangSmith和Weights&Biases各有17%的使用率，它们能够跟踪提示词的效果、检测模型漂移，这些是传统工具做不到的。\\n在推理优化方面，英伟达的TensorRT和Triton推理服务器加起来占了60%以上，说明英伟达在推理优化领域几乎垄断，毕竟它们的GPU可以说是行业标杆，软件和硬件也配合得好，能把速度和效率做到极致。在非英伟达的方案里，ONNXRuntime占了18%，它的优势是可以跨硬件，在CPU、GPU和其他加速器上都能跑，适合那些不想被英伟达绑定的公司。\\n在数据处理和特征工程方面，ApacheSpark和Kafka是绝对的主力，分别有44%和42%的公司在用，Spark适合大规模的批处理，Kafka适合实时流处理，这两个几乎是大数据处理的标配。但是小规模的数据处理，还是离不开Pandas，有41%的公司在用，它简单灵活，适合快速分析和原型开发。\\n\\n', '\\n在数据处理和特征工程方面，ApacheSpark和Kafka是绝对的主力，分别有44%和42%的公司在用，Spark适合大规模的批处理，Kafka适合实时流处理，这两个几乎是大数据处理的标配。但是小规模的数据处理，还是离不开Pandas，有41%的公司在用，它简单灵活，适合快速分析和原型开发。\\n\\n在编码辅助方面，GitHubCopilot几乎垄断了市场，75%的开发团队在用，它和VSCode深度集成，支持多种语言，而且背后有GitHub的海量代码训练，效果确实好。Cursor排名第二，有50%的公司在用，它更专注于AI驱动的编辑体验，比如实时重构代码，对很多开发者来说很顺手。其他一些工具，比如Codeium、Sourcegraph虽然也有用户，但是份额远不如前两个，说明编码辅助工具已经形成了“双巨头”的格局。\\n', '且背后有GitHub的海量代码训练，效果确实好。Cursor排名第二，有50%的公司在用，它更专注于AI驱动的编辑体验，比如实时重构代码，对很多开发者来说很顺手。其他一些工具，比如Codeium、Sourcegraph虽然也有用户，但是份额远不如前两个，说明编码辅助工具已经形成了“双巨头”的格局。\\n总结一下，从这份报告来看，2025年的AI开发已经进入了“深水区”，不再是拼谁能先做出一个AI功能，而是拼谁能把AI产品做稳定、做合规、做经济，同时搭建起能持续创新的团队和体系。AI原生公司凭借着天生的优势跑得更快，但AI赋能公司通过在现有产品中嵌入AI，也能找到自己的位置。在模型选择上，多模型策略成为了主流，而成本和定制化成了竞争的关键。定价和合规越来越复杂，需要平衡用户体验、成本和监管要求。人才依然是最大的瓶颈，尤其是既懂技术又懂业务的复合型人才。对想要入局的公司来说，有几个教训值得借鉴：首先要明确AI能解决的具体问题，不要为了AI而AI；其次是控制好API的成本，避免规模上去了利润没了；以及尽早搭建合规体系，别等监管来了再补课；最后就是要重视内部AI工具的落地，提升团队效率往往比对外宣传更重要。如今来看，AI已经不再是未来的趋势，而是现在的日常，怎么把它做好，考验的不只是技术能力，还有战略眼光、组织能力和成本意识。希望今天的内容能给大家一些启发，无论是创业还是职场，都能更好地把握AI带来的机会。感谢大家收看本期视频，我们下期再见。']\n"
     ]
    }
   ],
   "source": [
    "# 将文件内容读取并分块\n",
    "document_chunks = file_reader.get_content(max_token_len=600, cover_content=150)\n",
    "print(\"分块后的文档内容：\", document_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e410698d",
   "metadata": {},
   "source": [
    "## 10. 查看分块数量\n",
    "查看文档被分为了多少个块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682aeaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d06fb",
   "metadata": {},
   "source": [
    "## 11. 创建向量数据库\n",
    "创建向量存储实例，对文档进行向量化并持久化保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "301746e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建向量数据库\n",
    "vector_store = VectorStore(document=document_chunks)\n",
    "\n",
    "# 使用 OpenAI Embedding 模型对文档进行向量化\n",
    "embedding_model = OpenAIEmbedding()\n",
    "\n",
    "# 获取文档向量并存储\n",
    "vector_store.get_vector(embedding_model)\n",
    "\n",
    "# 持久化存储到本地\n",
    "vector_store.persist('storage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4fcc9",
   "metadata": {},
   "source": [
    "## 12. 查询相关文档\n",
    "使用向量相似度搜索来找到与用户查询最相关的文档片段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772add51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索结果： ['问题上。最近，曾经作为管理硅谷众多科技巨头家办的ICONIQ资本，抓住了这个转折点的时机，发布了一份长达68页的报告，拆解了300家正在开发AI产品的软件公司的实战经验。无论是AI原生公司，还是所谓的AI赋能公司，相信它们的踩坑经验、成功做法，都能带给我们很多的启发。今天大飞就来给大家分享一下。\\n\\n要聊AI产品的开发，首先我们得搞清楚现在市面上的AI公司到底有哪些类型。根据报告的调研，主要分为两类，分别是AI原生公司和AI赋能公司。AI原生公司指的是核心产品或商业模式完全由AI驱动的公司，它们的价值几乎都来自于模型训练、推理和持续的学习，这类公司在调研中占了32%，它们的特点是产品的迭代速度非常快。报告里提到，只有1%的AI原生公司还停留在产品发布前的阶段，而AI赋能公司则有11%卡在这个阶段；更关键的是，47%的AI原生产品已经进入了规模化的阶段，也就是说产品已经验证了市场契合度，正在快速扩大用户群和基础设施。这背后可能的原因是，AI原生公司在团队构成、基础设施和融资模式上更有优势，能够更快的跳过试错阶段，而AI赋能公司往往需要把AI“嫁接”到现有的工作流中，难免就会遇到更多的阻碍。']\n"
     ]
    }
   ],
   "source": [
    "# 模拟用户查询\n",
    "query = \"AI公司分为哪两种类型？\"\n",
    "result = vector_store.query(query, embedding_model)\n",
    "\n",
    "print(\"检索结果：\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ef2786",
   "metadata": {},
   "source": [
    "## 13. 生成AI回答\n",
    "使用GPT-4模型结合检索到的相关文档来生成问题的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ab0c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = GPT4oChat(api_key=api_key)\n",
    "question = 'AI公司分为哪两种类型？'\n",
    "answer = chat.chat(question, [], result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac0673",
   "metadata": {},
   "source": [
    "## 14. 显示生成的答案\n",
    "查看AI生成的回答内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c881e2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'参考段落的内容总结如下：\\n\\n根据ICONIQ资本发布的一份报告，目前市面上的AI公司主要分为两种类型：AI原生公司和AI赋能公司。AI原生公司是其核心产品或商业模式完全由AI驱动，且它们的商业价值来自于模型的训练、推理和持续学习。这类公司展现出较快的产品迭代速度，47%的产品已经进入规模化阶段。相对而言，AI赋能公司则需要将AI技术融入到现有的工作流中，面临更多的挑战和障碍。\\n\\n有用的回答是：AI公司分为两种类型，分别是AI原生公司和AI赋能公司。AI原生公司以AI为核心驱动力，而AI赋能公司则将AI技术应用于现有流程中。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1389865",
   "metadata": {},
   "source": [
    "## 15. 格式化显示答案\n",
    "使用Markdown格式美化显示AI生成的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58070ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "参考段落的内容总结如下：\n",
       "\n",
       "根据ICONIQ资本发布的一份报告，目前市面上的AI公司主要分为两种类型：AI原生公司和AI赋能公司。AI原生公司是其核心产品或商业模式完全由AI驱动，且它们的商业价值来自于模型的训练、推理和持续学习。这类公司展现出较快的产品迭代速度，47%的产品已经进入规模化阶段。相对而言，AI赋能公司则需要将AI技术融入到现有的工作流中，面临更多的挑战和障碍。\n",
       "\n",
       "有用的回答是：AI公司分为两种类型，分别是AI原生公司和AI赋能公司。AI原生公司以AI为核心驱动力，而AI赋能公司则将AI技术应用于现有流程中。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
